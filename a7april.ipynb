{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6f5a412-3a59-44fc-b277-0b9ea0799015",
   "metadata": {},
   "source": [
    "# Quetion : 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73f3520-5658-4aaf-af68-dc53adf015a1",
   "metadata": {},
   "source": [
    "The relationship between polynomial functions and kernel functions in machine learning algorithms, particularly in Support Vector Machines (SVM), is that polynomial functions can be used as kernel functions to map the data into a higher-dimensional feature space. Kernel functions enable SVM to find non-linear decision boundaries in the original feature space by implicitly projecting the data points into a higher-dimensional space.\n",
    "\n",
    "Polynomial kernel functions calculate the similarity between pairs of data points based on the polynomial expansion of their original features. The polynomial kernel function takes the form K(x, y) = (x^T * y + c)^d, where x and y are the input data points, c is a constant, and d is the degree of the polynomial.\n",
    "\n",
    "By using polynomial kernel functions, SVM can effectively capture non-linear relationships between features and find decision boundaries that are more complex than those possible with linear functions alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3591f448-5dbe-459f-9afa-9cbdf03c8968",
   "metadata": {},
   "source": [
    "# Quetion : 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff5ae7b-759c-4e89-be7c-8b7787b3d7ae",
   "metadata": {},
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Create an instance of the SVC classifier with polynomial kernel\n",
    "svm_classifier = svm.SVC(kernel='poly', degree=3)  # Use degree=3 for cubic polynomial kernel\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the testing data\n",
    "y_pred = svm_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe8a08d-fd43-49dc-8226-9fe875de2d9a",
   "metadata": {},
   "source": [
    "# Quetion : 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48018956-2479-4b54-be5d-28e18b3d2295",
   "metadata": {},
   "source": [
    " In Support Vector Regression (SVR), the value of epsilon (ε) represents the margin of tolerance around the regression line. Increasing the value of epsilon allows more data points to be within the margin of tolerance, leading to a larger tube around the regression line.\n",
    "\n",
    "However, increasing the value of epsilon does not necessarily affect the number of support vectors directly. The number of support vectors depends on the complexity of the data and the chosen regularization parameter (C). A larger C value tends to result in a smaller number of support vectors, while a smaller C value allows more support vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4884fed3-80be-4b04-9cab-9e2baf9b30e5",
   "metadata": {},
   "source": [
    "# Quetion : 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabdd0a4-2e9d-4ba0-bac6-dfce0e08744c",
   "metadata": {},
   "source": [
    "The choice of kernel function, C parameter, epsilon parameter, and gamma parameter in Support Vector Regression (SVR) can significantly affect the performance of the model:\n",
    "\n",
    "Kernel Function: Different kernel functions capture different types of relationships between features. The choice of kernel function should be based on the characteristics of the data and the problem at hand. Common kernel functions include linear, polynomial, radial basis function (RBF), and sigmoid. For example, if the data has non-linear relationships, a polynomial or RBF kernel may be more suitable.\n",
    "\n",
    "C Parameter: The C parameter controls the trade-off between fitting the training data and allowing deviations from the regression line. A larger C value leads to a narrower margin and fewer support vectors, resulting in a more sensitive model that closely fits the training data. Conversely, a smaller C value allows more support vectors and a wider margin, resulting in a more tolerant model with a smoother regression line.\n",
    "\n",
    "Epsilon Parameter: The epsilon parameter (ε) defines the margin of tolerance around the regression line. It determines the tube within which errors are considered acceptable. A larger epsilon allows more data points to be within the margin, leading to a wider tube and increased tolerance for errors.\n",
    "\n",
    "Gamma Parameter: The gamma parameter is specific to certain kernel functions, such as RBF. It defines the influence of a single training example and affects the shape of the decision boundary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b525ad9d-a0ed-49e0-9458-8db2e4e70b3c",
   "metadata": {},
   "source": [
    "# Quetion : 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7465464-b02c-4f3b-9f99-5929665e7d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd716764-ade0-4cf5-a2c6-441fe479157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64fb6005-0e00-422e-9dce-b4a38caf2079",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cee9c172-eec6-45f3-bf50-ed04fe5cef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4f8a901-a313-49f6-87bb-c645c71cdb59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d82fd8f5-2b7d-4de8-8bcf-3e06be26419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27dcc651-b975-4d0e-86c8-b13d4cb37723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0da277d-15b1-405b-9633-558e1b8b4043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10]}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=3)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6eaf18d-5091-457c-9896-c43944013f08",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m svm_tuned \u001b[38;5;241m=\u001b[39m SVC(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbest_params)\n\u001b[0;32m----> 2\u001b[0m svm_tuned\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_scaled\u001b[49m, y)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "svm_tuned = SVC(**best_params)\n",
    "svm_tuned.fit(X_trai, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464408e6-1188-4c9c-bc4b-1daf64907335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
